{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"idevji1/sherlock-holmes-stories\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjRblIyyaOx1",
        "outputId": "21e09266-2c34-4623-97cb-a5391da5aea2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/idevji1/sherlock-holmes-stories?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.93M/9.93M [00:00<00:00, 61.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/idevji1/sherlock-holmes-stories/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phOW6p987ugU",
        "outputId": "d3ef87d2-3366-4825-c643-4988f8069d59"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge) (1.17.0)\n",
            "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge import Rouge\n"
      ],
      "metadata": {
        "id": "3TwnxYmEAOOy",
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "zAtNCYSw7sT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the path - remove the leading space and add a trailing slash\n",
        "story_path = \"/root/.cache/kagglehub/datasets/idevji1/sherlock-holmes-stories/versions/1/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for root, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)  # Use os.path.join for proper path handling\n",
        "            with open(file_path) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line=='----------': break\n",
        "                    if line!='':txt.append(line)\n",
        "    return txt\n",
        "\n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines = \", len(stories))"
      ],
      "metadata": {
        "id": "Yikrnc0ZAORI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153f26c7-1124-4171-fd9f-25c8e58fef75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of lines =  430042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DNccSFBDqtOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f484dc74-3891-4f11-f97e-ff73433d8d52"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "metadata": {
        "id": "3LH0SWjMAOTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b2727c-c8ec-499a-b7e0-eaca78dad780"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words =  4664494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_markov_chain(text_corpus, order=2):\n",
        "    \"\"\"\n",
        "    Creates a Markov chain model from a list of words.\n",
        "\n",
        "    Args:\n",
        "        text_corpus: List of words in the corpus\n",
        "        order: The length of the n-gram to consider as state\n",
        "\n",
        "    Returns:\n",
        "        A dictionary representing the Markov model with transition probabilities\n",
        "    \"\"\"\n",
        "    # Initialize the model\n",
        "    model = {}\n",
        "\n",
        "    # We need enough words to create both a state and a next token\n",
        "    if len(text_corpus) <= order:\n",
        "        return model\n",
        "\n",
        "    # Build the model from the corpus\n",
        "    for i in range(len(text_corpus) - order):\n",
        "        # Create current state from n consecutive words\n",
        "        current = tuple(text_corpus[i:i+order])\n",
        "\n",
        "        # Get the next word\n",
        "        next_word = text_corpus[i+order]\n",
        "\n",
        "        # Add to model (initialize if needed)\n",
        "        if current not in model:\n",
        "            model[current] = {}\n",
        "\n",
        "        if next_word not in model[current]:\n",
        "            model[current][next_word] = 0\n",
        "\n",
        "        # Increment count\n",
        "        model[current][next_word] += 1\n",
        "\n",
        "    # Convert counts to probabilities\n",
        "    for state in model:\n",
        "        total_transitions = sum(model[state].values())\n",
        "        for next_word in model[state]:\n",
        "            model[state][next_word] /= total_transitions\n",
        "\n",
        "    return model\n",
        "\n",
        "def generate_text(markov_model, seed_words, length=100):\n",
        "    \"\"\"\n",
        "    Generate text using the Markov model.\n",
        "\n",
        "    Args:\n",
        "        markov_model: The Markov chain model\n",
        "        seed_words: List of words to start the generation\n",
        "        length: Number of words to generate\n",
        "\n",
        "    Returns:\n",
        "        A string of generated text\n",
        "    \"\"\"\n",
        "    # Ensure we have a valid seed\n",
        "    if len(seed_words) < len(next(iter(markov_model))):\n",
        "        return \"Seed text too short for this model\"\n",
        "\n",
        "    # Initialize with the seed words\n",
        "    current = tuple(seed_words[-len(next(iter(markov_model))):])\n",
        "    result = list(current)\n",
        "\n",
        "    # Generate text\n",
        "    for _ in range(length):\n",
        "        if current not in markov_model:\n",
        "            # If we reach a state with no transitions, break\n",
        "            break\n",
        "\n",
        "        # Choose the next word based on transition probabilities\n",
        "        transitions = markov_model[current]\n",
        "        next_word = random.choices(\n",
        "            list(transitions.keys()),\n",
        "            weights=list(transitions.values()),\n",
        "            k=1\n",
        "        )[0]\n",
        "\n",
        "        # Add to result\n",
        "        result.append(next_word)\n",
        "\n",
        "        # Update current state by sliding window\n",
        "        current = tuple(result[-len(current):])\n",
        "\n",
        "    return ' '.join(result)"
      ],
      "metadata": {
        "id": "3WcVRWJtAOXl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = build_markov_chain(cleaned_stories, order=2)\n",
        "\n",
        "# Generate text (starting with a seed like the first two words)\n",
        "generated_text = generate_text(model, cleaned_stories[:2], length=100)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "pp088ycuAOaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a4036f-3204-4af0-c967-d3c6b6dbd4bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the greek e will break her heart when she wouldnt do it but with the small morocco casket in which all of us glimmering in the jefferson hope felt his head sadly well well you have a word von bork clutched at my wrist and endeavoured to sound the dirge of our time so kindly read it yourself mycroft you can make nothing until i am unduly singing my own province this has been until lately lonelier than ever i confess that i should like to tell me where is the only servant i noticed it mr trelawney hope dropped his goose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of states\n",
        "print(\"number of states = \", len(model.keys()))\n",
        "\n",
        "# check transitions from a specific state\n",
        "the_game_state = ('the', 'servant')\n",
        "if the_game_state in model:\n",
        "    print(\"All possible transitions from 'the servant' state: \\n\")\n",
        "    print(model[the_game_state])\n",
        "else:\n",
        "    print(\"'the game' state not found in model\")\n",
        "\n",
        "# Generate stories using the generation function\n",
        "# For example, to start with \"dear holmes\"\n",
        "for i in range(20):\n",
        "    # Convert string to list of words for the seed\n",
        "    seed_words = \"dear holmes\".split()\n",
        "    # Generate text\n",
        "    story = generate_text(model, seed_words, length=8)\n",
        "    print(f\"{i}. {story}\")\n",
        "\n",
        "# Generate a longer story\n",
        "case_seed = \"the case\".split()\n",
        "long_story = generate_text(model, case_seed, length=100)\n",
        "print(long_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-_uHtsv6Pjl",
        "outputId": "9a8fcb49-306b-4e91-ca0c-aab67b85dae4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states =  208717\n",
            "All possible transitions from 'the servant' state: \n",
            "\n",
            "{'i': 0.08, 'there': 0.08, 'jose': 0.08, 'who': 0.08, 'had': 0.08, 'whats': 0.08, 'no': 0.08, 'and': 0.16, 'deposed': 0.08, 'pass': 0.06, 'seemed': 0.06, 'to': 0.08}\n",
            "0. dear holmes if it is marvellous i trust that they\n",
            "1. dear holmes am i to listen to the male relatives\n",
            "2. dear holmes oh very well then what clue could you\n",
            "3. dear holmes i have a key a moment to me\n",
            "4. dear holmes i think you would note he slapped the\n",
            "5. dear holmes what is his cap where was you you\n",
            "6. dear holmes and i have a clear run here of\n",
            "7. dear holmes if matters came to the lodge to employ\n",
            "8. dear holmes if it had not that i see also\n",
            "9. dear holmes i believe that the continued resistance of the\n",
            "10. dear holmes that there is a most skilful rider the\n",
            "11. dear holmes it is he cried can you pick any\n",
            "12. dear holmes i took the dead woman well if you\n",
            "13. dear holmes what is your own showing new to him\n",
            "14. dear holmes that you have afflicted a public danger they\n",
            "15. dear holmes i cant forget it all before you go\n",
            "16. dear holmes he asked i felt the stone holmes withdrew\n",
            "17. dear holmes my overstrung nerves failed me suddenly and as\n",
            "18. dear holmes he was writing busily that evening there was\n",
            "19. dear holmes my sister appear at the brass shines where\n",
            "the case as they came more rapidly than before where is he giving us the exact date is dr watson and as soon as it undoubtedly was in england is it madness mr holmes you take me three quarters of what remains for us to see if the earth travelled round the corner of cavendish a silver explorer and a marriage between us often if i would i said the treasurer as to wake up and down i followed him with a group of trees moaned and swung his leg on the parties mr holmes that i have no doubt that miss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedMarkovModel:\n",
        "    def __init__(self, max_order=3):\n",
        "        \"\"\"\n",
        "        Initialize an advanced Markov model with multiple n-gram orders.\n",
        "\n",
        "        Args:\n",
        "            max_order: Maximum n-gram order to consider\n",
        "        \"\"\"\n",
        "        self.max_order = max_order\n",
        "        self.models = {}  # Will store models of different orders\n",
        "        self.beginnings = []  # Sentence beginnings\n",
        "        self.endings = []  # Sentence endings\n",
        "        self.pos_transitions = defaultdict(Counter)  # POS tag transitions\n",
        "        self.word_by_pos = defaultdict(list)  # Words by POS tag\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"\n",
        "        Preprocesses raw text into sentences and words.\n",
        "\n",
        "        Args:\n",
        "            text: Raw text (list of lines or single string)\n",
        "\n",
        "        Returns:\n",
        "            List of sentences, where each sentence is a list of words\n",
        "        \"\"\"\n",
        "        if isinstance(text, list):\n",
        "            text = ' '.join(text)\n",
        "\n",
        "        # Split into sentences\n",
        "        sentences = sent_tokenize(text)\n",
        "        processed_sentences = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Clean and tokenize the sentence\n",
        "            clean_sentence = sentence.lower()\n",
        "            clean_sentence = re.sub(r\"[^\\w\\s\\.\\,\\!\\?\\'\\\"]\", \"\", clean_sentence)\n",
        "            words = word_tokenize(clean_sentence)\n",
        "\n",
        "            # Keep only sentences with actual content\n",
        "            if len(words) > 3:\n",
        "                processed_sentences.append(words)\n",
        "\n",
        "                # Store sentence beginnings and endings\n",
        "                self.beginnings.append(tuple(words[:min(self.max_order, len(words))]))\n",
        "                self.endings.append(tuple(words[-min(self.max_order, len(words)):]))\n",
        "\n",
        "        return processed_sentences\n",
        "\n",
        "    def build_pos_model(self, sentences):\n",
        "        \"\"\"\n",
        "        Builds a part-of-speech transition model.\n",
        "\n",
        "        Args:\n",
        "            sentences: List of sentences (each a list of words)\n",
        "        \"\"\"\n",
        "        for sentence in sentences:\n",
        "            # Tag parts of speech\n",
        "            pos_tags = pos_tag(sentence)\n",
        "\n",
        "            # Add words to POS dictionary\n",
        "            for word, tag in pos_tags:\n",
        "                self.word_by_pos[tag].append(word)\n",
        "\n",
        "            # Build POS transitions\n",
        "            for i in range(len(pos_tags) - 1):\n",
        "                current_tag = pos_tags[i][1]\n",
        "                next_tag = pos_tags[i + 1][1]\n",
        "                self.pos_transitions[current_tag][next_tag] += 1\n",
        "\n",
        "    def build_models(self, sentences):\n",
        "        \"\"\"\n",
        "        Builds variable-order Markov models.\n",
        "\n",
        "        Args:\n",
        "            sentences: List of sentences (each a list of words)\n",
        "        \"\"\"\n",
        "        # Build models for each order from 1 to max_order\n",
        "        for order in range(1, self.max_order + 1):\n",
        "            model = defaultdict(Counter)\n",
        "\n",
        "            for sentence in sentences:\n",
        "                # Skip sentences shorter than order+1\n",
        "                if len(sentence) <= order:\n",
        "                    continue\n",
        "\n",
        "                # Create n-grams\n",
        "                for i in range(len(sentence) - order):\n",
        "                    state = tuple(sentence[i:i+order])\n",
        "                    next_word = sentence[i+order]\n",
        "                    model[state][next_word] += 1\n",
        "\n",
        "            # Convert counts to probabilities\n",
        "            for state, transitions in model.items():\n",
        "                total = sum(transitions.values())\n",
        "                for next_word, count in transitions.items():\n",
        "                    model[state][next_word] = count / total\n",
        "\n",
        "            self.models[order] = dict(model)\n",
        "\n",
        "    def train(self, text):\n",
        "        \"\"\"\n",
        "        Train the model on the provided text.\n",
        "\n",
        "        Args:\n",
        "            text: Raw text to train on\n",
        "        \"\"\"\n",
        "        sentences = self.preprocess_text(text)\n",
        "        self.build_pos_model(sentences)\n",
        "        self.build_models(sentences)\n",
        "\n",
        "    def generate_next_word(self, state, current_order):\n",
        "        \"\"\"\n",
        "        Generate the next word using backoff mechanism.\n",
        "\n",
        "        Args:\n",
        "            state: Current state (tuple of words)\n",
        "            current_order: Current n-gram order\n",
        "\n",
        "        Returns:\n",
        "            Next word\n",
        "        \"\"\"\n",
        "        # Try to find the state in the current order model\n",
        "        if current_order > 0 and state[-current_order:] in self.models[current_order]:\n",
        "            transitions = self.models[current_order][state[-current_order:]]\n",
        "            next_word = random.choices(\n",
        "                list(transitions.keys()),\n",
        "                weights=list(transitions.values()),\n",
        "                k=1\n",
        "            )[0]\n",
        "            return next_word\n",
        "\n",
        "        # Backoff to a lower order model\n",
        "        elif current_order > 1:\n",
        "            return self.generate_next_word(state, current_order - 1)\n",
        "\n",
        "        # If all else fails, return a random word\n",
        "        else:\n",
        "            return random.choice([next_word for next_words in self.models[1].values()\n",
        "                                 for next_word in next_words.keys()])\n",
        "\n",
        "    def generate_pos_aware_word(self, prev_tag):\n",
        "        \"\"\"\n",
        "        Generate a word based on part-of-speech constraints.\n",
        "\n",
        "        Args:\n",
        "            prev_tag: Previous POS tag\n",
        "\n",
        "        Returns:\n",
        "            Word and its POS tag\n",
        "        \"\"\"\n",
        "        # Get possible next tags\n",
        "        if prev_tag in self.pos_transitions:\n",
        "            next_tags = list(self.pos_transitions[prev_tag].keys())\n",
        "            weights = list(self.pos_transitions[prev_tag].values())\n",
        "            next_tag = random.choices(next_tags, weights=weights, k=1)[0]\n",
        "        else:\n",
        "            next_tag = random.choice(list(self.word_by_pos.keys()))\n",
        "\n",
        "        # Get a word for that tag\n",
        "        if next_tag in self.word_by_pos and self.word_by_pos[next_tag]:\n",
        "            word = random.choice(self.word_by_pos[next_tag])\n",
        "        else:\n",
        "            # Fallback\n",
        "            all_words = [w for words in self.word_by_pos.values() for w in words]\n",
        "            word = random.choice(all_words) if all_words else \"the\"\n",
        "\n",
        "        return word, next_tag\n",
        "\n",
        "    def generate_text(self, length=100, seed=None, use_pos=True):\n",
        "        \"\"\"\n",
        "        Generate text using the trained model.\n",
        "\n",
        "        Args:\n",
        "            length: Number of words to generate\n",
        "            seed: Optional starting words (list)\n",
        "            use_pos: Whether to use POS information\n",
        "\n",
        "        Returns:\n",
        "            Generated text\n",
        "        \"\"\"\n",
        "        if not self.models:\n",
        "            return \"Model not trained yet.\"\n",
        "\n",
        "        # Initialize with seed or random beginning\n",
        "        if seed and len(seed) > 0:\n",
        "            current = tuple(seed[-self.max_order:] if len(seed) >= self.max_order else seed)\n",
        "            result = list(seed)\n",
        "        else:\n",
        "            current = random.choice(self.beginnings)\n",
        "            result = list(current)\n",
        "\n",
        "        current_pos = pos_tag(result)[-1][1] if use_pos and result else \"NN\"\n",
        "\n",
        "        # Generate text\n",
        "        i = 0\n",
        "        while i < length:\n",
        "            # Check if we should end the sentence\n",
        "            if tuple(result[-min(len(result), self.max_order):]) in self.endings and i > length // 2:\n",
        "                if len(result) > 0 and result[-1][-1] not in \".!?\":\n",
        "                    result[-1] = result[-1] + \".\"\n",
        "                break\n",
        "\n",
        "            # Get next word\n",
        "            if use_pos and random.random() < 0.7:  # 70% chance to use POS model\n",
        "                next_word, current_pos = self.generate_pos_aware_word(current_pos)\n",
        "            else:\n",
        "                next_word = self.generate_next_word(tuple(result[-self.max_order:]), self.max_order)\n",
        "\n",
        "            # Add word to result\n",
        "            result.append(next_word)\n",
        "            i += 1\n",
        "\n",
        "            # Update current state\n",
        "            current = tuple(result[-self.max_order:])\n",
        "\n",
        "        # Ensure sentence ends with punctuation\n",
        "        if len(result) > 0 and result[-1][-1] not in \".!?\":\n",
        "            result[-1] = result[-1] + \".\"\n",
        "\n",
        "        # Apply some basic post-processing to fix issues\n",
        "        text = ' '.join(result)\n",
        "        text = re.sub(r'\\s+([.,!?])', r'\\1', text)  # Fix spacing before punctuation\n",
        "        text = re.sub(r'\\.+', '.', text)  # Remove multiple periods\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "\n",
        "        # Capitalize first letter of sentences\n",
        "        sentences = re.split(r'([.!?])', text)\n",
        "        processed_text = \"\"\n",
        "        for i in range(0, len(sentences) - 1, 2):\n",
        "            if sentences[i].strip():\n",
        "                sentence = sentences[i].strip()\n",
        "                sentence = sentence[0].upper() + sentence[1:]\n",
        "                processed_text += sentence + sentences[i+1] + \" \"\n",
        "\n",
        "        return processed_text.strip()\n",
        "\n",
        "    def evaluate_bleu(self, reference_texts, generated_text, n=4):\n",
        "        \"\"\"\n",
        "        Evaluate generated text using BLEU score.\n",
        "\n",
        "        Args:\n",
        "            reference_texts: List of reference texts\n",
        "            generated_text: Generated text to evaluate\n",
        "            n: Maximum n-gram order to consider\n",
        "\n",
        "        Returns:\n",
        "            BLEU score\n",
        "        \"\"\"\n",
        "        # Tokenize texts\n",
        "        references = [word_tokenize(text.lower()) for text in reference_texts]\n",
        "        candidate = word_tokenize(generated_text.lower())\n",
        "\n",
        "        # Calculate BLEU score with smoothing\n",
        "        weights = [1/n] * n\n",
        "        smoothing = SmoothingFunction().method1\n",
        "        return sentence_bleu(references, candidate, weights=weights, smoothing_function=smoothing)\n",
        "\n",
        "    def evaluate_rouge(self, reference_text, generated_text):\n",
        "        \"\"\"\n",
        "        Evaluate generated text using ROUGE score.\n",
        "\n",
        "        Args:\n",
        "            reference_text: Reference text\n",
        "            generated_text: Generated text to evaluate\n",
        "\n",
        "        Returns:\n",
        "            ROUGE scores (dictionary)\n",
        "        \"\"\"\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(generated_text, reference_text)\n",
        "        return scores[0]\n",
        "\n",
        "    def calculate_perplexity(self, test_text, order=2):\n",
        "        \"\"\"\n",
        "        Calculate perplexity of the model on test text.\n",
        "\n",
        "        Args:\n",
        "            test_text: Text to evaluate on\n",
        "            order: N-gram order to use\n",
        "\n",
        "        Returns:\n",
        "            Perplexity score (lower is better)\n",
        "        \"\"\"\n",
        "        if order not in self.models:\n",
        "            return float('inf')\n",
        "\n",
        "        sentences = self.preprocess_text(test_text)\n",
        "        log_prob_sum = 0\n",
        "        word_count = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            if len(sentence) <= order:\n",
        "                continue\n",
        "\n",
        "            word_count += len(sentence) - order\n",
        "\n",
        "            for i in range(len(sentence) - order):\n",
        "                state = tuple(sentence[i:i+order])\n",
        "                next_word = sentence[i+order]\n",
        "\n",
        "                # Calculate probability with smoothing\n",
        "                if state in self.models[order] and next_word in self.models[order][state]:\n",
        "                    prob = self.models[order][state][next_word]\n",
        "                else:\n",
        "                    # Smoothing: use a small probability if transition not found\n",
        "                    prob = 1e-10\n",
        "\n",
        "                log_prob_sum += np.log2(prob)\n",
        "\n",
        "        if word_count == 0:\n",
        "            return float('inf')\n",
        "\n",
        "        perplexity = 2 ** (-log_prob_sum / word_count)\n",
        "        return perplexity\n",
        "\n"
      ],
      "metadata": {
        "id": "epVSi0JG7OcT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demonstrate_advanced_markov(text_data):\n",
        "    # Initialize and train the model\n",
        "    model = AdvancedMarkovModel(max_order=3)\n",
        "    model.train(text_data)\n",
        "\n",
        "    # Generate text with different seeds\n",
        "    print(\"Generated text with random seed:\")\n",
        "    generated1 = model.generate_text(length=150)\n",
        "    print(generated1)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Generated text with seed 'Sherlock Holmes':\")\n",
        "    generated2 = model.generate_text(length=150, seed=[\"Sherlock\", \"Holmes\"])\n",
        "    print(generated2)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"Evaluation metrics:\")\n",
        "    print(\"--------------------\")\n",
        "    # Split the text into train/test\n",
        "    sentences = model.preprocess_text(text_data)\n",
        "    random.shuffle(sentences)\n",
        "    split = int(0.8 * len(sentences))\n",
        "    train_sentences = sentences[:split]\n",
        "    test_sentences = sentences[split:]\n",
        "\n",
        "    # Convert back to text for evaluation\n",
        "    test_text = \" \".join([\" \".join(sentence) for sentence in test_sentences])\n",
        "\n",
        "    # Calculate perplexity\n",
        "    perplexity = model.calculate_perplexity(test_text)\n",
        "    print(f\"Perplexity: {perplexity:.2f}\")\n",
        "\n",
        "    # Calculate BLEU\n",
        "    reference_texts = [\" \".join(sentence) for sentence in test_sentences[:5]]\n",
        "    bleu_score = model.evaluate_bleu(reference_texts, generated1)\n",
        "    print(f\"BLEU score: {bleu_score:.4f}\")\n",
        "\n",
        "    # Calculate ROUGE if test_sentences are not empty\n",
        "    if test_sentences:\n",
        "        reference_text = \" \".join([\" \".join(sentence) for sentence in test_sentences[:10]])\n",
        "        rouge_scores = model.evaluate_rouge(reference_text, generated1)\n",
        "        print(f\"ROUGE-1 F1: {rouge_scores['rouge-1']['f']:.4f}\")\n",
        "        print(f\"ROUGE-2 F1: {rouge_scores['rouge-2']['f']:.4f}\")\n",
        "        print(f\"ROUGE-L F1: {rouge_scores['rouge-l']['f']:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "Mzgx362F7OfF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_model = demonstrate_advanced_markov(stories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdt5Hckd7Ohs",
        "outputId": "9eeccff3-e83a-49b9-8c51-52c111bbf5dc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text with random seed:\n",
            "`` i 'm sorry, holmes. '' left so nearly cost us, and marked and the as the 'can day and an exceedingly sir that fright. Had to tell the direction dreadful, finding of the all the left stick, and macdonald 's night, and many being the same caltrops staggered it was several sort and said? '' '' was ever had. As other would have all sheridan operations, friend for the preference that it, and, with ten its i was never, dying man.\n",
            "\n",
            "\n",
            "Generated text with seed 'Sherlock Holmes':\n",
            "Sherlock Holmes, whose 'tweendecks of possible family, and once often to try to have. '' succeeded he approached this lamp watson, even and for a long time that shoulders, bent at after them. Must look tell to miss see that a fellow that i never he was have it single it cut light upon and very seldom it seldom seemed touch. ' '' corresponded brown yourself went a bit so. '.\n",
            "\n",
            "\n",
            "Evaluation metrics:\n",
            "--------------------\n",
            "Perplexity: 13.94\n",
            "BLEU score: 0.0099\n",
            "ROUGE-1 F1: 0.2154\n",
            "ROUGE-2 F1: 0.0213\n",
            "ROUGE-L F1: 0.1949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o-sJIkSZ7OkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_OsAtW47OmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ub0o2TCN7OpA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}